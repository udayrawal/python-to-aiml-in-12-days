"""
üìò Day 10 ‚Äì Pandas Data Cleaning & GroupBy Analysis

What I learned today:
1Ô∏è‚É£ Handling Missing Data
   - Detected missing values in DataFrames
   - Used `fillna()` with mean imputation

2Ô∏è‚É£ Data Cleaning
   - Removed duplicate rows using `drop_duplicates()`
   - Ensured dataset consistency

3Ô∏è‚É£ GroupBy Analysis
   - Grouped data using categorical columns
   - Applied aggregate functions (mean, max, min)
   - Compared performance across groups

Focus:
‚Üí Cleaning real-world data before analysis  
‚Üí Using groupby for analytical insights  
‚Üí Building ML-ready datasets
"""

# --------------------------------------------------
# Sample Dataset
# --------------------------------------------------

import pandas as pd

data = {
    "student": ["A", "B", "C", "D", "E"],
    "score":   [85, None, 78, 90, 32],
    "passed":  [True, True, True, True, False]
}

df = pd.DataFrame(data)

print("\n---------------------- Original DataFrame -----------------------------\n")
print(df)

# --------------------------------------------------
# 1. Handling Missing Data
# --------------------------------------------------

df["score"] = df["score"].fillna(df["score"].mean())

print("\n---------------------- After Handling Missing Data -----------------------------\n")
print(df)

# --------------------------------------------------
# 2. Remove Duplicates
# --------------------------------------------------

df = df.drop_duplicates()

print("\n---------------------- After Removing Duplicates -----------------------------\n")
print(df)

# --------------------------------------------------
# 3. GroupBy Analysis
# --------------------------------------------------

result = df.groupby("passed")["score"].agg(["mean", "max", "min"])

print("\n---------------------- GroupBy Analysis (Passed vs Failed) -----------------------------\n")
print(result)

print("\n---------------------- Thank You -----------------------------\n")

# End of the File: 04_pandas/day10_practice.py